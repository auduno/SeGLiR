<!doctype html>
<html>
<head>
<meta charset="utf-8">
<title>Reference</title>
<link rel="stylesheet" href="./styles/styles.css">
<link rel="stylesheet" href="./styles/coderay.css">
<script src="./javascripts/scale.fix.js"></script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
<script src="./javascripts/slimbox2.js"></script>
<link rel="stylesheet" href="./styles/slimbox2.css" type="text/css" media="screen" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<!--[if lt IE 9]>
<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>-
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="wrapper">
<header>
<h1>
<a href="http://github.com/auduno/seglir/">SeGLiR</a></h1>
<p>Javascript library for rapid A/B-testing with Sequential Generalized Likelihood Ratio Tests</p>
<p class="view">
<a href="https://github.com/auduno/seglir">View the Project on GitHub <small>auduno/SeGLiR</small></a></p>
<ul>
<li><a href="https://github.com/auduno/seglir/zipball/master">Download <strong>ZIP File</strong></a></li>
<li><a href="https://github.com/auduno/seglir/tarball/master">Download <strong>TAR Ball</strong></a></li>
<li><a href="https://github.com/auduno/seglir">Fork On <strong>GitHub</strong></a></li>
</ul>
</header>
<section>
<h1>Library Reference</h1>

<!--<h2 id="process">Flow</h2>-->

<p>SeGLiR is a javascript implementation of hypothesis testing (aka A/B-testing) with Sequential Generalized Likelihood Ratio Tests. The Sequential Generalized Likelihood Ratio Test is a family of sequential hypothesis test that will stop as soon as we are able to reject a hypothesis, while still keeping type-1 and type-2 error guarantees. Compared to fixed-sample size tests, this usually gives a significant decrease in the needed samplesize, at the cost of some loss of precision in estimates when the test is done. The test has been shown<sup><a href="#fn1">1</a></sup> to be <em>uniformly first-order asymptotically optimal</em> with regard to minimizing samplesize for tests based on a exponential family parameter. For some idea about the difference in expected samplesize, here's numbers from a comparison of bernoulli proportions with a fixed sample-size test and a sequential GLR test, both with $\alpha$-level 0.05, $\beta$-level 0.10 and $\delta$ = 0.01.</p>

<p style="text-align:center">
  <a href="../images/samplesize1.png" rel="lightbox" title="Expected Samplesize"><img src="../images/samplesize1.png" width="400px" height="305px">
  </a>
</p>

<h2 id="math">Mathematical details</h2>

<p>Mathematically, we have one or more random variables $X$ with a distribution dependent on some (possible multivariate) parameter $\theta$. We also have two hypotheses $H_0 : \theta \in \Theta_0$ and $H_A : \theta \in \Theta_A$ and want to find out which is most likely based on samples we collect, while keeping some guarantees on how many Type-1 or Type-2 errors we can expect to make. A Sequential GLR test will stop as soon as:</p>

<!--<p>\begin{aligned}
L_{na} \geq b_0 \;\mathrm{or}\; L_{nb} \geq b_1
\end{aligned}</p>-->

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
<mrow>
  <msub>
    <mi>L</mi>
    <mrow>
      <mi>n</mi>
      <mi>a</mi>
    </mrow>
  </msub>
  <mo>&geq;</mo>
  <msub>
    <mi>b</mi>
    <mn>0</mn>
  </msub>
  <mspace width="0.278em" />
  <mtext>or</mtext>
  <mspace width="0.278em" />
  <msub>
    <mi>L</mi>
    <mrow>
      <mi>n</mi>
      <mi>b</mi>
    </mrow>
  </msub>
  <mo>&geq;</mo>
  <msub>
    <mi>b</mi>
    <mn>1</mn>
  </msub>
</mrow>
</math>

<p>where</p>

<!--<p>\begin{aligned} L_{na} = \frac{\sup_{\theta \in \Theta} \prod_{i=1}^{n} f_{\theta}(X_i) }{\sup_{\theta_0 \in \Theta_0} \prod_{i=1}^{n} f_{\theta_0}(X_i) } \; \mathrf{and} \;L_{nb} = \frac{\sup_{\theta \in \Theta} \prod_{i=1}^{n} f_{\theta}(X_i)}{\sup_{\theta_A \in \Theta_A} \prod_{i=1}^{n} f_{\theta_A}(X_i)} \end{aligned}</p>-->

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
<mrow>
  <msub>
    <mi>L</mi>
    <mrow>
      <mi>n</mi>
      <mi>a</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <mfrac linethickness="1">
    <mrow>
      <mstyle displaystyle="true">
        <munder>
          <mi>sup</mi>
          <mrow>
            <mi>&theta;</mi>
            <mo>&isin;</mo>
            <mi>&Theta;</mi>
          </mrow>
        </munder>
      </mstyle>
      <mstyle displaystyle="true">
        <munderover>
          <mo>&prod;</mo>
          <mrow>
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mi>n</mi>
        </munderover>
      </mstyle>
      <msub>
        <mi>f</mi>
        <mi>&theta;</mi>
      </msub>
      <mrow>
        <mo form="prefix">(</mo>
        <msub>
          <mi>X</mi>
          <mi>i</mi>
        </msub>
        <mo form="postfix">)</mo>
      </mrow>
    </mrow>
    <mrow>
      <mstyle displaystyle="true">
        <munder>
          <mi>sup</mi>
          <mrow>
            <msub>
              <mi>&theta;</mi>
              <mn>0</mn>
            </msub>
            <mo>&isin;</mo>
            <msub>
              <mi>&Theta;</mi>
              <mn>0</mn>
            </msub>
          </mrow>
        </munder>
      </mstyle>
      <mstyle displaystyle="true">
        <munderover>
          <mo>&prod;</mo>
          <mrow>
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mi>n</mi>
        </munderover>
      </mstyle>
      <msub>
        <mi>f</mi>
        <mrow>
          <msub>
            <mi>&theta;</mi>
            <mn>0</mn>
          </msub>
        </mrow>
      </msub>
      <mrow>
        <mo form="prefix">(</mo>
        <msub>
          <mi>X</mi>
          <mi>i</mi>
        </msub>
        <mo form="postfix">)</mo>
      </mrow>
    </mrow>
  </mfrac>
  <mspace width="0.278em" />
  <mtext>,</mtext>
  <mspace width="0.278em" />
  <msub>
    <mi>L</mi>
    <mrow>
      <mi>n</mi>
      <mi>b</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <mfrac linethickness="1">
    <mrow>
      <mstyle displaystyle="true">
        <munder>
          <mi>sup</mi>
          <mrow>
            <mi>&theta;</mi>
            <mo>&isin;</mo>
            <mi>&Theta;</mi>
          </mrow>
        </munder>
      </mstyle>
      <mstyle displaystyle="true">
        <munderover>
          <mo>&prod;</mo>
          <mrow>
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mi>n</mi>
        </munderover>
      </mstyle>
      <msub>
        <mi>f</mi>
        <mi>&theta;</mi>
      </msub>
      <mrow>
        <mo form="prefix">(</mo>
        <msub>
          <mi>X</mi>
          <mi>i</mi>
        </msub>
        <mo form="postfix">)</mo>
      </mrow>
    </mrow>
    <mrow>
      <mstyle displaystyle="true">
        <munder>
          <mi>sup</mi>
          <mrow>
            <msub>
              <mi>&theta;</mi>
              <mi>A</mi>
            </msub>
            <mo>&isin;</mo>
            <msub>
              <mi>&Theta;</mi>
              <mi>A</mi>
            </msub>
          </mrow>
        </munder>
      </mstyle>
      <mstyle displaystyle="true">
        <munderover>
          <mo>&prod;</mo>
          <mrow>
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mi>n</mi>
        </munderover>
      </mstyle>
      <msub>
        <mi>f</mi>
        <mrow>
          <msub>
            <mi>&theta;</mi>
            <mi>A</mi>
          </msub>
        </mrow>
      </msub>
      <mrow>
        <mo form="prefix">(</mo>
        <msub>
          <mi>X</mi>
          <mi>i</mi>
        </msub>
        <mo form="postfix">)</mo>
      </mrow>
    </mrow>
  </mfrac>
</mrow>
</math>

<p>and $b_0$ and $b_1$ are thresholds precalculated so that the test fulfills the wanted type-1 and type-2 error guarantees. If $L_{na} > b_0$ at the time of stopping, the null hypothesis is rejected (and the alternative hypothesis accepted), while if $L_{nb} > b_1$ the alternative hypothesis is rejected (and the null hypothesis accepted). Typically there is also a small predefined indifference region of size $\delta$ between $\Theta_0$ and $\Theta_A$ where we don't care about our type-1 and type-2 error guarantees. This is equivalent to saying that we are only interested in detecting differences larger than $\delta$. Note that there is a tradeoff between $\delta$ and worst-case samplesize - when $\delta$ is small, worst-case samplesize may be large, while if $\delta$ is large, worst-case samplesize may be small.</p>

<p>Unlike fixed sample-size tests, the thresholds $b_0$ and $b_1$ for a given $\alpha$-level and $\beta$-level are not analytically calculable, therefore simulation has to be used to calculate these thresholds. Since this can be a time-demanding affair, especially when $\delta$ is small, this library includes some precalculated thresholds for the most common $\alpha$- and $\beta$-levels. See below for exactly which.</p>

<p>Note that like all sequential tests with a stopping rule, the usual maximum likelihood estimates of the parameter $\theta$ will be biased. Therefore, this library implements the Whitehead method to bias-correct estimates, which can be called with <em>estimate()</em> when the test is done. Confidence intervals are calculated with bias-adjusted bootstrapping, but note that coverage may be poor for some parts of the parameter space.</p>

<h2>Installation and usage</h2>

<p>It is easiest to install SeGLiR via node package manager (make sure you have node.js installed):</p>

<pre><code>npm install seglir
</code></pre>

<p>and load via <em>require</em> in node.js.</p>

<pre><code>var glr = require('seglir');
</code></pre>

<p>Generally the library follows the template of creating an instance of a test via :</p>

<pre><code>var test = glr.test(<em>type</em>, <em>sides</em>, <em>indifference_size</em>, <em>alpha</em>, <em>beta</em>);
</code></pre>

<p>where <em>type</em> is the type of the test (for instance "bernoulli"), <em>sides</em> is "two-sided" or "one-sided", <em>indifference_size</em> is the size of the indifference region, <em>alpha</em> is the desired type-1 error, and <em>beta</em> is the desired type-2 error. These parameters may vary depending on the type of test, so check documentation for the test type below. Note that in a lot of cases, calculating the thresholds b_0 and b_1 in order to get the wanted type-1 and type-2 error may take a long time, so it's an advantage to select alpha and beta values where the thresholds are precalculated, see this under the specific test.</p>

<p>From the returned instance of the test, you can add datasamples via the function <em>addData()</em>:

<pre><code>test.addData({x : 0});
test.addData({x : 1, y : 0});
test.addData({y : 0});
</code></pre>

If this function returns the strings "true" or "false", the test has finished. "true" means the null hypothesis was accepted, while "false" means the alternative hypothesis was accepted. When the test is done, get estimates of the parameters of the test by calling:</p>

<pre><code>test.estimate();
</code></pre>

<p>This library currently implements these types of Sequential GLR tests:</p>
<ul>
  <li>Comparing two bernoulli proportions</li>
  <li>Comparing two gaussian means, with unknown but equal variance</li>
  <li>Selecting the best arm in a two-armed bandit setting, with Î´-PAC guarantees</li>
</ul>
<p>There are some differences between the functions for these tests, so consult more detailed reference for each test below.</p>

<h2>Comparison of two bernoulli proportions</h2>

<p>In these tests we assume that we have two random variables, $X$ and $Y$, where $X$ is bernoulli distributed with unknown parameter $p_1$ and $Y$ is bernoulli distributed with unknown parameter $p_2$, and we want to do some inference on the parameters $p_1$ and $p_2$. These tests are what is commonly used in web page testing, for instance for testing conversion.</p>

<p>In the two-sided test we test the hypotheses $H_0 : p_1 = p_2$ versus $H_A : |p_1 - p_2| > \delta$ (where $\delta > 0$ is the size of the indifference region), while in the one-sided test we test the hypotheses $H_0 : p_1 < p_2 - \delta$ versus $H_A : p_1 > p_2 + \delta$. Note that in both cases, this is equivalent to saying we are interested in detecting differences between $p_1$ and $p_2$ larger than $\delta > 0$.</p>

<p>Test instantiation:</p>

<ul>
<li><strong>test(</strong>"bernoulli", <em>sides</em>, <em>indifference</em>, <em>alpha</em>, <em>beta</em><strong>)</strong><ul>
    <li><em>sides</em> : "one-sided" or "two-sided"</li>
    <li><em>indifference</em> : the value of $\delta$, i.e. the size of the indifference region</li>
    <li><em>alpha</em> : the wanted level of type-1 errors</li>
    <li><em>beta</em> : the wanted level of type-2 errors</li>
  </ul>
</li>
</ul>

<p>Instance functions</p>

<ul>
<li><em><strong>getResults()</strong></em> : returns an object with sufficient statistics, likelihood ratio statistics, as well as information on whether the test is done.</li>
<li><em><strong>pValue()</strong></em> : if the test is done, this returns a simulated p-value.</li>
<li><em><strong>confInterval()</strong></em> : if the test is done, this returns a bootstrap confidence interval of the difference between $p_1$ and $p_2$.</li>
<li><em><strong>estimate()</strong></em> : if the test is done, this returns whitehead bias-adjusted estimates of $p_1$, $p_2$ and $p_1 - p_2$ respectively.</li>
<li><em><strong>getData()</strong></em> : returns two arrays with the sequences of samples of $X$ and $Y$ collected so far.</li>
<li><em><strong>addData(</strong>{x : 1, y : 1}<strong>)</strong></em> : add data points from samples of $X$ and $Y$ respectively. Note that it's possible to add samples from $X$ and $Y$ separately. Returns <em>undefined</em> until test is finished, when it will return either <em>"true"</em> ($H_A$ was rejected) or <em>"false"</em> ($H_0$ was rejected) as a string. Note that after the test is finished, the instance will still store new data points added internally, but test statistics and conclusion will not be updated. All stored data points collected can be retrieved via <em>getData()</em>.</li>
<li><em><strong>expectedSamplesize(</strong>p1, p2<strong>)</strong></em> : simulates the expected sample size needed for concluding a test with true parameters $p_1$ and $p_2$.</li>
<li><em><strong>maxSamplesize()</strong></em> : returns the worst-case maximum samplesize of this test.</li>
<li><em><strong>properties()</strong></em> : returns an object with properties of this test that were specified on initialization, such as <em>type</em>, <em>sides</em>, <em>indifference size</em>, <em>alpha</em> and <em>beta</em>.</li>
</ul>

<p>Precalculated thresholds:</p>

<ul>
  <li>Two-sided:</li>
</ul>

<p>A simple example:</p>

<pre><code>var glr = require('seglir');
var test = glr.test("bernoulli","two-sided",0.01,0.05,0.10);
// add data from samples as they come in
test.addData({x : 0});
test.addData({y : 1});
test.addData({y : 1, x : 0});
test.addData({x : 0, y : 1});
test.addData({y : 1, x : 0}); // returns result "false", i.e. we reject the null-hypothesis
// get estimates of p_1, p_2 and p_1-p_2
test.estimate(); // returns [0, 1, -1]
</code></pre>

<sup>Footnotes:</sup><br/>
<sup id="fn1">1. Tartakovsky, Nikiforov, Basseville : Sequential Analysis, CRC press 2014, <a href="http://books.google.no/books?id=zhsbBAAAQBAJ&lpg=PP1&pg=PA254#v=onepage&q&f=false">Theorem 5.4.1</a></sup>

<!--<h3><a href="/">&lsaquo;&nbsp;&nbsp;back&nbsp;</a></h3>-->
</section>
<footer>
<p>This project is maintained by <a href="https://github.com/auduno">auduno</a></p>
<p><small>Theme originated from <a href="https://github.com/orderedlist">orderedlist</a></small></p>
</footer>
</div>
<!--[if !IE]><script>fixScale(document);</script><!--<![endif]-->
</body>
</html>
